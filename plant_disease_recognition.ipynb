{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "sourceId": 2394131,
          "sourceType": "datasetVersion",
          "datasetId": 1447507
        }
      ],
      "dockerImageVersionId": 30120,
      "isInternetEnabled": false,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "source": [
        "\n",
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES\n",
        "# TO THE CORRECT LOCATION (/kaggle/input) IN YOUR NOTEBOOK,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "\n",
        "import os\n",
        "import sys\n",
        "from tempfile import NamedTemporaryFile\n",
        "from urllib.request import urlopen\n",
        "from urllib.parse import unquote, urlparse\n",
        "from urllib.error import HTTPError\n",
        "from zipfile import ZipFile\n",
        "import tarfile\n",
        "import shutil\n",
        "\n",
        "CHUNK_SIZE = 40960\n",
        "DATA_SOURCE_MAPPING = 'plant-disease-recognition-dataset:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-data-sets%2F1447507%2F2394131%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240402%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240402T075408Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D93283ab4607b0b339cd8936ffce61dc8bb9766a8624b54e0327a3cd8aa830987ea9cc2eb0a7ca894108f2af00677ddd53f69954c2be141e7603dbd073d06d47dadf39dbbb449e70c511ea277484cbc38441c8619e0a78e283d3a58493ef7e2a6e50838b9d23a68995731d1f0698d31c664c89cb9eb90f4a62fafc7f9fd59a7d4e7586771282b4ccc9a05b9b2a6d1b1428dcf23549646744475a40a0217a2e0d9559d8e7931c9f31cfccce7fecf482c59797e278a4483559bbbfb06e12a3027c090e492c9507899d64dcf55fbb74f2b25fd0a8240af878b850a7916feee721aaab6f72e97537200d0b591cd976a4bf9b2c07858c1c2a98cf7291c6e1c7ae05cc6'\n",
        "\n",
        "KAGGLE_INPUT_PATH='/kaggle/input'\n",
        "KAGGLE_WORKING_PATH='/kaggle/working'\n",
        "KAGGLE_SYMLINK='kaggle'\n",
        "\n",
        "!umount /kaggle/input/ 2> /dev/null\n",
        "shutil.rmtree('/kaggle/input', ignore_errors=True)\n",
        "os.makedirs(KAGGLE_INPUT_PATH, 0o777, exist_ok=True)\n",
        "os.makedirs(KAGGLE_WORKING_PATH, 0o777, exist_ok=True)\n",
        "\n",
        "try:\n",
        "  os.symlink(KAGGLE_INPUT_PATH, os.path.join(\"..\", 'input'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "try:\n",
        "  os.symlink(KAGGLE_WORKING_PATH, os.path.join(\"..\", 'working'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "\n",
        "for data_source_mapping in DATA_SOURCE_MAPPING.split(','):\n",
        "    directory, download_url_encoded = data_source_mapping.split(':')\n",
        "    download_url = unquote(download_url_encoded)\n",
        "    filename = urlparse(download_url).path\n",
        "    destination_path = os.path.join(KAGGLE_INPUT_PATH, directory)\n",
        "    try:\n",
        "        with urlopen(download_url) as fileres, NamedTemporaryFile() as tfile:\n",
        "            total_length = fileres.headers['content-length']\n",
        "            print(f'Downloading {directory}, {total_length} bytes compressed')\n",
        "            dl = 0\n",
        "            data = fileres.read(CHUNK_SIZE)\n",
        "            while len(data) > 0:\n",
        "                dl += len(data)\n",
        "                tfile.write(data)\n",
        "                done = int(50 * dl / int(total_length))\n",
        "                sys.stdout.write(f\"\\r[{'=' * done}{' ' * (50-done)}] {dl} bytes downloaded\")\n",
        "                sys.stdout.flush()\n",
        "                data = fileres.read(CHUNK_SIZE)\n",
        "            if filename.endswith('.zip'):\n",
        "              with ZipFile(tfile) as zfile:\n",
        "                zfile.extractall(destination_path)\n",
        "            else:\n",
        "              with tarfile.open(tfile.name) as tarfile:\n",
        "                tarfile.extractall(destination_path)\n",
        "            print(f'\\nDownloaded and uncompressed: {directory}')\n",
        "    except HTTPError as e:\n",
        "        print(f'Failed to load (likely expired) {download_url} to path {destination_path}')\n",
        "        continue\n",
        "    except OSError as e:\n",
        "        print(f'Failed to load {download_url} to path {destination_path}')\n",
        "        continue\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "qDp0LFIS6DOg"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import requirements"
      ],
      "metadata": {
        "id": "qOnUIQ-h6DOi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q addict"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "execution": {
          "iopub.status.busy": "2021-07-21T10:33:56.904245Z",
          "iopub.execute_input": "2021-07-21T10:33:56.904493Z",
          "iopub.status.idle": "2021-07-21T10:34:05.174243Z",
          "shell.execute_reply.started": "2021-07-21T10:33:56.90447Z",
          "shell.execute_reply": "2021-07-21T10:34:05.173238Z"
        },
        "trusted": true,
        "id": "GksCgrFU6DOi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.optim import AdamW\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "from torchvision import models\n",
        "from PIL import Image\n",
        "import albumentations as A\n",
        "from albumentations.pytorch.transforms import ToTensorV2\n",
        "import numpy as np\n",
        "import os\n",
        "import random\n",
        "from addict import Dict\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "import logging"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-07-21T10:34:05.177776Z",
          "iopub.execute_input": "2021-07-21T10:34:05.178069Z",
          "iopub.status.idle": "2021-07-21T10:34:08.211104Z",
          "shell.execute_reply.started": "2021-07-21T10:34:05.17804Z",
          "shell.execute_reply": "2021-07-21T10:34:08.210299Z"
        },
        "trusted": true,
        "id": "ZoAjBg156DOi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Functions"
      ],
      "metadata": {
        "id": "ymsnwae96DOi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def seed_everything(seed:int=42) -> None:\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONASSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "\n",
        "\n",
        "def get_optimizer(model:torch.nn.Module, name:str=\"SGD\", parameters:dict={}) -> torch.optim.Optimizer:\n",
        "    optimizers = {\n",
        "        \"SGD\": torch.optim.SGD,\n",
        "        \"AdamW\": torch.optim.AdamW,\n",
        "        \"Adam\": torch.optim.Adam,\n",
        "        \"RMSprop\": torch.optim.RMSprop,\n",
        "    }\n",
        "\n",
        "    instance = optimizers.get(name, \"SGD\")\n",
        "    optimizer = instance(model.parameters(), **parameters)\n",
        "\n",
        "    return optimizer\n",
        "\n",
        "\n",
        "def get_scheduler(optimizer:torch.optim.Optimizer, name:str, parameters:dict):\n",
        "    schedulers = {\n",
        "        \"ReduceLROnPlateau\": torch.optim.lr_scheduler.ReduceLROnPlateau,\n",
        "        \"LambdaLR\": torch.optim.lr_scheduler.LambdaLR,\n",
        "        \"StepLR\": torch.optim.lr_scheduler.StepLR,\n",
        "        \"ExponentialLR\": torch.optim.lr_scheduler.ExponentialLR,\n",
        "        \"MultiplicativeLR\": torch.optim.lr_scheduler.MultiplicativeLR,\n",
        "        \"MultiStepLR\": torch.optim.lr_scheduler.MultiStepLR,\n",
        "    }\n",
        "\n",
        "    instance = schedulers[name]\n",
        "    scheduler = instance(optimizer, **parameters)\n",
        "\n",
        "    return scheduler\n",
        "\n",
        "\n",
        "\n",
        "def accuracy_score(predictions:torch.Tensor, targets:torch.Tensor) -> torch.Tensor:\n",
        "    amount = (predictions == targets).sum()\n",
        "    accuracy = amount / targets.size(0)\n",
        "\n",
        "    return accuracy\n",
        "\n",
        "\n",
        "\n",
        "def hide_spines(ax, spines=[\"top\", \"right\", \"left\", \"bottom\"]):\n",
        "    for spine in spines:\n",
        "        ax.spines[spine].set_visible(False)\n",
        "\n",
        "def plot_images(rows, cols, indexes, class_=0):\n",
        "    min_index = min(indexes)\n",
        "    max_index = max(indexes)\n",
        "    fig = plt.figure(figsize=(3*cols, 3*rows))\n",
        "    for i in range(*indexes):\n",
        "        item = train_dataset[i]\n",
        "        image = item.image\n",
        "        label = item.label\n",
        "\n",
        "        if label == class_:\n",
        "            ax = fig.add_subplot(rows, cols, (i - min_index)+1)\n",
        "            ax.imshow(image.permute(1, 2, 0))\n",
        "            ax.xaxis.set_visible(False)\n",
        "            ax.yaxis.set_visible(False)\n",
        "\n",
        "    fig.text(s=f\"{train_dataset.labels[class_]} leaves\", x=0.125, y=0.9, fontweight=\"bold\", fontfamily=\"serif\", fontsize=20)\n",
        "    fig.show()\n",
        "\n",
        "\n",
        "def get_logger(name:str=__name__, format:str=\"[%(asctime)s][%(levelname)s]: %(message)s\") -> logging.Logger:\n",
        "    logger = logging.getLogger(name)\n",
        "    logger.setLevel(logging.INFO)\n",
        "    formatter = logging.Formatter(format)\n",
        "\n",
        "    file_handler = logging.FileHandler(name)\n",
        "    file_handler.setLevel(logging.INFO)\n",
        "    file_handler.setFormatter(formatter)\n",
        "\n",
        "    stream_handler = logging.StreamHandler()\n",
        "    stream_handler.setLevel(logging.INFO)\n",
        "    stream_handler.setFormatter(formatter)\n",
        "\n",
        "    logger.addHandler(stream_handler)\n",
        "    logger.addHandler(file_handler)\n",
        "\n",
        "    logger.propagate = False\n",
        "\n",
        "    return logger"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-07-21T10:34:08.212932Z",
          "iopub.execute_input": "2021-07-21T10:34:08.213284Z",
          "iopub.status.idle": "2021-07-21T10:34:08.23125Z",
          "shell.execute_reply.started": "2021-07-21T10:34:08.213247Z",
          "shell.execute_reply": "2021-07-21T10:34:08.229955Z"
        },
        "trusted": true,
        "id": "ZeKpZUmY6DOj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Configs"
      ],
      "metadata": {
        "id": "21lHRC-k6DOk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "config = Dict({\n",
        "    \"train_path\": \"../input/plant-disease-recognition-dataset/Train/Train\",\n",
        "    \"test_path\": \"../input/plant-disease-recognition-dataset/Test/Test\",\n",
        "    \"validation_path\": \"../input/plant-disease-recognition-dataset/Validation/Validation\"\n",
        "})\n",
        "\n",
        "train_config = Dict({\n",
        "    \"device\": torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"),\n",
        "    \"epochs\": 5,\n",
        "    \"seed\": 2021,\n",
        "    \"image_shape\": (128, 128),\n",
        "    \"image_channels\": 3,\n",
        "    \"num_workers\": 0,\n",
        "    \"batch_size\": 32,\n",
        "\n",
        "    \"augmentations\": A.Compose([\n",
        "        A.HorizontalFlip(p=0.5),\n",
        "        A.VerticalFlip(p=0.5),\n",
        "        #A.Blur(p=1),\n",
        "        ToTensorV2(),\n",
        "    ]),\n",
        "    \"optimizer\": {\n",
        "        \"type\": \"AdamW\",\n",
        "        \"parameters\": {\n",
        "            \"lr\": 0.001,\n",
        "            \"weight_decay\": 0.01,\n",
        "        }\n",
        "    },\n",
        "\n",
        "    \"scheduler\": {\n",
        "        \"type\": \"ReduceLROnPlateau\",\n",
        "        \"parameters\": {\n",
        "            \"patience\": 2,\n",
        "            \"mode\": \"min\",\n",
        "            \"factor\": 0.1,\n",
        "        }\n",
        "    }\n",
        "})\n",
        "\n",
        "\n",
        "seed_everything(train_config.seed)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-07-21T11:35:39.944505Z",
          "iopub.execute_input": "2021-07-21T11:35:39.944828Z",
          "iopub.status.idle": "2021-07-21T11:35:39.953851Z",
          "shell.execute_reply.started": "2021-07-21T11:35:39.9448Z",
          "shell.execute_reply": "2021-07-21T11:35:39.951466Z"
        },
        "trusted": true,
        "id": "GS2ssGjH6DOk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset"
      ],
      "metadata": {
        "id": "AbnE2GDL6DOk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class PlantDiseaseDataset(Dataset):\n",
        "    def __init__(self, path, augmentations=None, image_shape=(256, 256), channels=\"RGB\"):\n",
        "        self.__images_labels = []\n",
        "        self.image_shape = image_shape\n",
        "        self.channels = channels\n",
        "        self.augmentations = augmentations\n",
        "\n",
        "        if os.path.exists(path):\n",
        "            self.labels = os.listdir(path)\n",
        "            for label in self.labels:\n",
        "                label_path = os.path.join(path, label)\n",
        "                if os.path.isdir(label_path):\n",
        "                    files = os.listdir(label_path)\n",
        "                    for file in files:\n",
        "                        if file.endswith(\"jpg\") or file.endswith(\"png\"):\n",
        "                            image_path = os.path.join(label_path, file)\n",
        "                            self.__images_labels.append((image_path, label))\n",
        "                        else:\n",
        "                            pass\n",
        "                else:\n",
        "                    pass\n",
        "\n",
        "        else:\n",
        "            pass\n",
        "\n",
        "    def _load(self, path, channels=\"RGB\"):\n",
        "        width, height = self.image_shape\n",
        "        loader = A.Compose([\n",
        "            A.Resize(width=width, height=height),\n",
        "            ToTensorV2(),\n",
        "        ])\n",
        "\n",
        "        image_array = np.array(Image.open(path).convert(channels))\n",
        "        return loader(image=image_array)[\"image\"]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.__images_labels)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        path, label = self.__images_labels[index]\n",
        "        image = self._load(path)\n",
        "\n",
        "        if self.augmentations is not None:\n",
        "            image = image.permute(1, 2, 0).numpy()\n",
        "            image = self.augmentations(image=image)[\"image\"]\n",
        "\n",
        "        label = self.labels.index(label)\n",
        "\n",
        "        return Dict({\n",
        "            \"image\": image,\n",
        "            \"label\": label,\n",
        "        })\n",
        "\n",
        "\n",
        "def collate_fn(batch):\n",
        "    all_images, all_labels = [], []\n",
        "    for item in batch:\n",
        "        image = item.image\n",
        "        label = item.label\n",
        "\n",
        "        all_images.append(item.image.tolist())\n",
        "        all_labels.append(label)\n",
        "\n",
        "    return {\n",
        "        \"images\": torch.tensor(all_images),\n",
        "        \"labels\": torch.tensor(all_labels, dtype=torch.int8)\n",
        "    }\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-07-21T11:35:40.593703Z",
          "iopub.execute_input": "2021-07-21T11:35:40.59402Z",
          "iopub.status.idle": "2021-07-21T11:35:40.607368Z",
          "shell.execute_reply.started": "2021-07-21T11:35:40.593991Z",
          "shell.execute_reply": "2021-07-21T11:35:40.606445Z"
        },
        "trusted": true,
        "id": "EhN55GP06DOk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exploratory Data Analysis"
      ],
      "metadata": {
        "id": "DKnjFPqe6DOk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = PlantDiseaseDataset(path=config.train_path,\n",
        "                                    image_shape=train_config.image_shape,\n",
        "                                    channels=train_config.image_channels)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-07-21T11:35:41.178483Z",
          "iopub.execute_input": "2021-07-21T11:35:41.178804Z",
          "iopub.status.idle": "2021-07-21T11:35:41.189182Z",
          "shell.execute_reply.started": "2021-07-21T11:35:41.178776Z",
          "shell.execute_reply": "2021-07-21T11:35:41.188403Z"
        },
        "trusted": true,
        "id": "ERTvsR5_6DOk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label_pathes = [os.path.join(config.train_path, label) for label in train_dataset.labels]\n",
        "label_files = [os.listdir(path) for path in label_pathes]\n",
        "amount = [len(files) for files in label_files]\n",
        "\n",
        "palette = sns.color_palette([\"#5FB924\", \"#AB4800\", \"#B2BBAC\"])\n",
        "fig = plt.figure(figsize=(7, 7))\n",
        "ax = fig.add_subplot()\n",
        "ax.grid(color=\"lightgrey\", axis=\"both\", alpha=0.8, zorder=0)\n",
        "sns.barplot(x=train_dataset.labels, y=amount, palette=palette,  ec=\"#000\", linewidth=1.5, zorder=2, ax=ax)\n",
        "ax.xaxis.set_tick_params(labelsize=14, size=0, pad=10)\n",
        "ax.yaxis.set_tick_params(labelsize=12, size=0, pad=5)\n",
        "ax.set_yticks(list(range(0, 450, 50)))\n",
        "ax.set_title(f\"Classes Distribution\", fontsize=20, fontweight=\"bold\", fontfamily=\"serif\", loc=\"left\", y=1.01)\n",
        "ax.set_xlabel(\"Classes\", fontsize=15, fontfamily=\"serif\", labelpad=5)\n",
        "ax.set_ylabel(\"Count\", fontsize=15, fontfamily=\"serif\", labelpad=5)\n",
        "hide_spines(ax)\n",
        "fig.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-07-21T11:35:42.618973Z",
          "iopub.execute_input": "2021-07-21T11:35:42.619307Z",
          "iopub.status.idle": "2021-07-21T11:35:42.753432Z",
          "shell.execute_reply.started": "2021-07-21T11:35:42.619277Z",
          "shell.execute_reply": "2021-07-21T11:35:42.75247Z"
        },
        "trusted": true,
        "id": "OW2yl5Ci6DOk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_images(rows=5, cols=5, indexes=(0, 25), class_=0)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-07-21T11:35:43.058424Z",
          "iopub.execute_input": "2021-07-21T11:35:43.058734Z",
          "iopub.status.idle": "2021-07-21T11:35:49.264829Z",
          "shell.execute_reply.started": "2021-07-21T11:35:43.058707Z",
          "shell.execute_reply": "2021-07-21T11:35:49.26369Z"
        },
        "trusted": true,
        "id": "AHp8EWpA6DOk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_images(rows=5, cols=5, indexes=(500, 525), class_=1)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-07-21T11:35:49.266393Z",
          "iopub.execute_input": "2021-07-21T11:35:49.266725Z",
          "iopub.status.idle": "2021-07-21T11:35:55.453913Z",
          "shell.execute_reply.started": "2021-07-21T11:35:49.266691Z",
          "shell.execute_reply": "2021-07-21T11:35:55.453157Z"
        },
        "trusted": true,
        "id": "z04H4Iru6DOl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_images(rows=5, cols=5, indexes=(len(train_dataset)-25, len(train_dataset)), class_=2)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-07-21T11:35:55.455613Z",
          "iopub.execute_input": "2021-07-21T11:35:55.456107Z",
          "iopub.status.idle": "2021-07-21T11:36:02.249113Z",
          "shell.execute_reply.started": "2021-07-21T11:35:55.45607Z",
          "shell.execute_reply": "2021-07-21T11:36:02.248257Z"
        },
        "trusted": true,
        "id": "WWRKe6Ma6DOl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprate the Datasets & Data Loaders"
      ],
      "metadata": {
        "id": "-9wxx3XG6DOl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = PlantDiseaseDataset(path=config.train_path,\n",
        "                                    augmentations=train_config.augmentations,\n",
        "                                    image_shape=train_config.image_shape,\n",
        "                                    channels=train_config.image_channels)\n",
        "\n",
        "validation_dataset = PlantDiseaseDataset(path=config.validation_path,\n",
        "                                         augmentations=train_config.augmentations,\n",
        "                                         image_shape=train_config.image_shape,\n",
        "                                         channels=train_config.image_channels)\n",
        "\n",
        "test_dataset = PlantDiseaseDataset(path=config.test_path,\n",
        "                                   augmentations=train_config.augmentations,\n",
        "                                   image_shape=train_config.image_shape,\n",
        "                                   channels=train_config.image_channels)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-07-21T11:36:02.250535Z",
          "iopub.execute_input": "2021-07-21T11:36:02.250958Z",
          "iopub.status.idle": "2021-07-21T11:36:02.282048Z",
          "shell.execute_reply.started": "2021-07-21T11:36:02.250925Z",
          "shell.execute_reply": "2021-07-21T11:36:02.28122Z"
        },
        "trusted": true,
        "id": "VdLFudwi6DOl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(dataset=train_dataset,\n",
        "                          batch_size=train_config.batch_size,\n",
        "                          num_workers=train_config.num_workers,\n",
        "                          pin_memory=True,\n",
        "                          shuffle=True,\n",
        "                          collate_fn=collate_fn)\n",
        "\n",
        "validation_loader = DataLoader(dataset=validation_dataset,\n",
        "                               batch_size=train_config.batch_size*2,\n",
        "                               num_workers=train_config.num_workers,\n",
        "                               pin_memory=True,\n",
        "                               shuffle=False,\n",
        "                               collate_fn=collate_fn)\n",
        "\n",
        "test_loader = DataLoader(dataset=test_dataset,\n",
        "                         batch_size=train_config.batch_size*2,\n",
        "                         num_workers=train_config.num_workers,\n",
        "                         pin_memory=True,\n",
        "                         shuffle=False,\n",
        "                         collate_fn=collate_fn)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-07-21T11:36:02.283422Z",
          "iopub.execute_input": "2021-07-21T11:36:02.28395Z",
          "iopub.status.idle": "2021-07-21T11:36:02.291054Z",
          "shell.execute_reply.started": "2021-07-21T11:36:02.283912Z",
          "shell.execute_reply": "2021-07-21T11:36:02.290298Z"
        },
        "trusted": true,
        "id": "XiYA6Xil6DOl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Modelling"
      ],
      "metadata": {
        "id": "gLZuIQqz6DOl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class PlantDiseaseModel(nn.Module):\n",
        "    def __init__(self, classes=2):\n",
        "        super(PlantDiseaseModel, self).__init__()\n",
        "        self.model = models.resnet34(pretrained=True)\n",
        "\n",
        "        for parameter in self.model.parameters():\n",
        "            parameter.require_grad = False\n",
        "\n",
        "        in_features = self.model.fc.in_features\n",
        "        self.model.fc = nn.Sequential(\n",
        "            nn.Linear(in_features=in_features, out_features=classes),\n",
        "            nn.Softmax(dim=1)\n",
        "        )\n",
        "\n",
        "    def forward(self, image):\n",
        "        output = self.model(image)\n",
        "        return output"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-07-21T11:36:02.292473Z",
          "iopub.execute_input": "2021-07-21T11:36:02.292887Z",
          "iopub.status.idle": "2021-07-21T11:36:02.299933Z",
          "shell.execute_reply.started": "2021-07-21T11:36:02.292851Z",
          "shell.execute_reply": "2021-07-21T11:36:02.299111Z"
        },
        "trusted": true,
        "id": "AKpYyAZ06DOl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Trainer:\n",
        "    def __init__(self, model, criterion, optimizer,  metric, scheduler=None, logger=None, device=\"cpu\"):\n",
        "        self.model = model\n",
        "        self.criterion = criterion\n",
        "        self.optimizer = optimizer\n",
        "        self.scheduler = scheduler\n",
        "        self.logger = logger\n",
        "        self.device = torch.device(device)\n",
        "        self.best_validation_loss = 0\n",
        "        self.metric = metric\n",
        "        self.history = Dict({})\n",
        "\n",
        "    def __log(self, logs):\n",
        "        for k, v in logs.items():\n",
        "            if k not in self.history:\n",
        "                self.history[k] = []\n",
        "\n",
        "            self.history[k].append(v)\n",
        "\n",
        "    def evaluate(self, loader):\n",
        "        loss, score, length = 0, 0, len(loader)\n",
        "\n",
        "        self.model.to(self.device)\n",
        "        with torch.no_grad():\n",
        "            loop = tqdm(loader, position=0, colour=\"BLACK\", desc=f\"Evaluating: \", leave=True)\n",
        "            for batch in loop:\n",
        "                if self.device.type != \"cpu\": torch.cuda.empty_cache()\n",
        "                self.model.eval()\n",
        "\n",
        "                images = batch[\"images\"].float().to(self.device)\n",
        "                labels = batch[\"labels\"].long().to(\"cpu\")\n",
        "\n",
        "                probabilities = self.model(images).float().to(\"cpu\")\n",
        "                predictions = torch.argmax(probabilities, dim=1).detach()\n",
        "\n",
        "                batch_loss = self.criterion(probabilities, labels)\n",
        "                loss += batch_loss.item()\n",
        "\n",
        "                batch_score = self.metric(predictions, labels).item()\n",
        "                score += batch_score\n",
        "\n",
        "            loss /= length\n",
        "            score /= length\n",
        "\n",
        "        return loss, score\n",
        "\n",
        "\n",
        "\n",
        "    def fit(self, train_loader, validation_loader=None, epochs=10):\n",
        "        self.model.to(self.device)\n",
        "        train_length = len(train_loader)\n",
        "\n",
        "        for epoch in range(epochs):\n",
        "            epoch_loss, epoch_score = 0, 0\n",
        "\n",
        "            loop = tqdm(train_loader, position=0, colour=\"BLACK\", leave=True, desc=f\"Epoch [{epoch+1}/{epochs}]: \")\n",
        "            for batch in loop:\n",
        "                if self.device.type != \"cpu\": torch.cuda.empty_cache()\n",
        "                self.optimizer.zero_grad()\n",
        "                self.model.train()\n",
        "\n",
        "                images = batch[\"images\"].float().to(self.device)\n",
        "                labels = batch[\"labels\"].long().to(\"cpu\")\n",
        "\n",
        "                probabilities = self.model(images).float().to(\"cpu\")\n",
        "                predictions = torch.argmax(probabilities, dim=1).detach()\n",
        "\n",
        "                batch_loss = self.criterion(probabilities, labels)\n",
        "                epoch_loss += batch_loss.item()\n",
        "\n",
        "                batch_score = self.metric(predictions, labels).item()\n",
        "                epoch_score += batch_score\n",
        "\n",
        "                batch_loss.backward()\n",
        "                self.optimizer.step()\n",
        "\n",
        "            epoch_loss /= train_length\n",
        "            epoch_score /= train_length\n",
        "\n",
        "            self.__log({\"train_losses\": epoch_loss, \"train_scores\": epoch_score})\n",
        "            if self.logger is not None: self.logger.info(f\"Epoch [{epoch+1}/{epochs}]: Loss: {epoch_loss} | Metric: {epoch_score}\")\n",
        "\n",
        "            if validation_loader is not None:\n",
        "                validation_loss, validation_score = self.evaluate(validation_loader)\n",
        "                self.__log({\"validation_losses\": validation_loss, \"validation_scores\": validation_score})\n",
        "                if self.logger is not None: self.logger.info(f\"Validation Epoch [{epoch+1}/{epochs}]: Loss: {validation_loss} | Metric: {validation_score}\")\n",
        "\n",
        "\n",
        "\n",
        "                if self.scheduler is not None:\n",
        "                    if isinstance(self.scheduler, torch.optim.lr_scheduler.ReduceLROnPlateau):\n",
        "                        self.scheduler.step(validation_loss)\n",
        "                    else:\n",
        "                        self.scheduler.step()\n",
        "\n",
        "                    if self.logger is not None:\n",
        "                        lr = self.optimizer.param_groups[0][\"lr\"]\n",
        "                        self.logger.info(f\"Epoch [{epoch+1}/{epochs}] Learning Rate: {lr}\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-07-21T12:57:33.040731Z",
          "iopub.execute_input": "2021-07-21T12:57:33.041056Z",
          "iopub.status.idle": "2021-07-21T12:57:33.061332Z",
          "shell.execute_reply.started": "2021-07-21T12:57:33.041025Z",
          "shell.execute_reply": "2021-07-21T12:57:33.060354Z"
        },
        "trusted": true,
        "id": "fuxAXS916DOl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = PlantDiseaseModel(classes=len(train_dataset.labels))\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = get_optimizer(model=model,\n",
        "                          name=train_config.optimizer.type,\n",
        "                          parameters=train_config.optimizer.parameters)\n",
        "\n",
        "if \"scheduler\" in train_config:\n",
        "    scheduler = get_scheduler(optimizer=optimizer,\n",
        "                              name=train_config.scheduler.type,\n",
        "                              parameters=train_config.scheduler.parameters)\n",
        "\n",
        "trainer_logger = get_logger(\"trainer\")\n",
        "trainer = Trainer(model=model,\n",
        "                  criterion=criterion,\n",
        "                  metric=accuracy_score,\n",
        "                  optimizer=optimizer,\n",
        "                  scheduler=scheduler,\n",
        "                  logger=trainer_logger,\n",
        "                  device=train_config.device)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-07-21T12:57:33.357644Z",
          "iopub.execute_input": "2021-07-21T12:57:33.357977Z",
          "iopub.status.idle": "2021-07-21T12:57:33.917285Z",
          "shell.execute_reply.started": "2021-07-21T12:57:33.357945Z",
          "shell.execute_reply": "2021-07-21T12:57:33.916193Z"
        },
        "trusted": true,
        "id": "vYyADS9N6DOl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.fit(train_loader=train_loader,\n",
        "            validation_loader=validation_loader,\n",
        "            epochs=train_config.epochs)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-07-21T12:57:43.95473Z",
          "iopub.execute_input": "2021-07-21T12:57:43.955042Z",
          "iopub.status.idle": "2021-07-21T13:20:06.83936Z",
          "shell.execute_reply.started": "2021-07-21T12:57:43.955012Z",
          "shell.execute_reply": "2021-07-21T13:20:06.838454Z"
        },
        "trusted": true,
        "id": "8H_f5h7m6DOl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs_ = range(1, train_config.epochs+1)\n",
        "fig = plt.figure(figsize=(10, 5))\n",
        "ax = fig.add_subplot()\n",
        "ax.grid(color=\"lightgrey\", axis=\"both\", alpha=0.8, zorder=0)\n",
        "sns.lineplot(x=epochs_, y=trainer.history.train_losses, color=\"red\", marker=\"o\", label=\"Train Loss\", zorder=2, ax=ax)\n",
        "sns.lineplot(x=epochs_, y=trainer.history.validation_losses, color=\"blue\", marker=\"o\", label=\"Validation Loss\", zorder=2, ax=ax)\n",
        "ax.set_title(\"Train & Validation Losses\", fontsize=20, fontweight=\"bold\", fontfamily=\"serif\", loc=\"left\", y=1.05)\n",
        "hide_spines(ax)\n",
        "ax.xaxis.set_tick_params(labelsize=12, size=0, pad=10)\n",
        "ax.yaxis.set_tick_params(labelsize=12, size=0, pad=5)\n",
        "ax.set_xlabel(\"Epochs\", fontsize=15, fontfamily=\"serif\", labelpad=10)\n",
        "ax.set_ylabel(\"Loss\", fontsize=15, fontfamily=\"serif\", labelpad=5)\n",
        "ax.legend()\n",
        "fig.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-07-21T13:22:09.302442Z",
          "iopub.execute_input": "2021-07-21T13:22:09.302764Z",
          "iopub.status.idle": "2021-07-21T13:22:09.55674Z",
          "shell.execute_reply.started": "2021-07-21T13:22:09.302733Z",
          "shell.execute_reply": "2021-07-21T13:22:09.555545Z"
        },
        "trusted": true,
        "id": "qP6uRdt36DOl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig = plt.figure(figsize=(10, 5))\n",
        "ax = fig.add_subplot()\n",
        "ax.grid(color=\"lightgrey\", axis=\"both\", alpha=0.8, zorder=0)\n",
        "sns.lineplot(x=epochs_, y=trainer.history.train_scores, color=\"red\", marker=\"o\", label=\"Train Accuracy\", zorder=2, ax=ax)\n",
        "sns.lineplot(x=epochs_, y=trainer.history.validation_scores, color=\"blue\", marker=\"o\", label=\"Validation Accuracy\", zorder=2, ax=ax)\n",
        "ax.set_title(\"Train & Validation Accuracy\", fontsize=20, fontweight=\"bold\", fontfamily=\"serif\", loc=\"left\", y=1.05)\n",
        "hide_spines(ax)\n",
        "ax.xaxis.set_tick_params(labelsize=12, size=0, pad=10)\n",
        "ax.yaxis.set_tick_params(labelsize=12, size=0, pad=5)\n",
        "ax.set_xlabel(\"Epochs\", fontsize=15, fontfamily=\"serif\", labelpad=10)\n",
        "ax.set_ylabel(\"Accuracy\", fontsize=15, fontfamily=\"serif\", labelpad=5)\n",
        "ax.legend()\n",
        "fig.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-07-21T13:22:01.96494Z",
          "iopub.execute_input": "2021-07-21T13:22:01.965289Z",
          "iopub.status.idle": "2021-07-21T13:22:02.195412Z",
          "shell.execute_reply.started": "2021-07-21T13:22:01.965258Z",
          "shell.execute_reply": "2021-07-21T13:22:02.194465Z"
        },
        "trusted": true,
        "id": "qWIsvK_U6DOm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pa_yc2t56DOm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}